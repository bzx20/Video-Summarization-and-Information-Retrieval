{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from typing import NamedTuple\n",
    "\n",
    "import scenedetect\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import whisper\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoProcessor, MllamaForConditionalGeneration\n",
    "from yt_dlp import YoutubeDL\n",
    "\n",
    "\n",
    "class VideoSummarizerConfig(NamedTuple):\n",
    "\n",
    "    workdir: Path\n",
    "    content_detector_threshold: float = 27\n",
    "    num_keyframes_per_scene: int = 1\n",
    "\n",
    "\n",
    "class VideoSummarizer:\n",
    "\n",
    "    @staticmethod\n",
    "    def from_youtube_url(\n",
    "        youtube_url: str, config: VideoSummarizerConfig\n",
    "    ) -> \"VideoSummarizer\":\n",
    "        config.workdir.mkdir(exist_ok=True)\n",
    "\n",
    "        video_path: Path | None = None\n",
    "\n",
    "        def hook(info):\n",
    "            nonlocal video_path\n",
    "            video_path = Path(info[\"filename\"])\n",
    "\n",
    "        with YoutubeDL(\n",
    "            {\n",
    "                \"format\": \"best\",\n",
    "                \"progress_hooks\": [hook],\n",
    "                \"outtmpl\": f\"{str(config.workdir)}/%(title)s.%(ext)s\",\n",
    "            }\n",
    "        ) as ydl:\n",
    "            ydl.download([youtube_url])\n",
    "\n",
    "        return VideoSummarizer(config, Path(video_path.name))\n",
    "\n",
    "    def __init__(\n",
    "        self, config: VideoSummarizerConfig, video_path: Path | None = None\n",
    "    ) -> None:\n",
    "        self.config = config\n",
    "        self.config.workdir.mkdir(exist_ok=True)\n",
    "\n",
    "        if video_path is not None:\n",
    "            (self.config.workdir / \"video_path.txt\").write_text(str(video_path))\n",
    "\n",
    "    def get_video_path(self) -> Path:\n",
    "        return self.config.workdir / Path(\n",
    "            (self.config.workdir / \"video_path.txt\").read_text().strip()\n",
    "        )\n",
    "\n",
    "    def get_video_title(self) -> str:\n",
    "        return self.get_video_path().stem\n",
    "\n",
    "    def get_scene_data(self) -> dict:\n",
    "        with (self.config.workdir / \"scenes.json\").open() as fp:\n",
    "            return json.load(fp)\n",
    "\n",
    "    def get_scene_data_with_labels(self) -> dict:\n",
    "        with (self.config.workdir / \"scenes_with_labels.json\").open() as fp:\n",
    "            return json.load(fp)\n",
    "\n",
    "    def get_scene_data_with_descriptions(self) -> dict:\n",
    "        with (self.config.workdir / \"scenes_with_descriptions.json\").open() as fp:\n",
    "            return json.load(fp)\n",
    "\n",
    "    def get_summary(self) -> str:\n",
    "        return (self.config.workdir / \"summary.txt\").read_text()\n",
    "\n",
    "    def detect_scenes(self) -> None:\n",
    "        video = scenedetect.open_video(str(self.get_video_path()))\n",
    "        scene_manager = scenedetect.SceneManager()\n",
    "        scene_manager.add_detector(\n",
    "            scenedetect.ContentDetector(\n",
    "                threshold=self.config.content_detector_threshold\n",
    "            )\n",
    "        )\n",
    "        scene_manager.detect_scenes(video)\n",
    "\n",
    "        scene_list = scene_manager.get_scene_list()\n",
    "\n",
    "        scenes_dir = self.config.workdir / \"scenes\"\n",
    "        scenes_dir.mkdir(exist_ok=True)\n",
    "        scenedetect.split_video_ffmpeg(\n",
    "            str(self.get_video_path()), scene_list, scenes_dir\n",
    "        )\n",
    "\n",
    "        keyframes_dir = self.config.workdir / \"keyframes\"\n",
    "        keyframes_dir.mkdir(exist_ok=True)\n",
    "        scenedetect.scene_manager.save_images(\n",
    "            scene_list,\n",
    "            video,\n",
    "            self.config.num_keyframes_per_scene,\n",
    "            output_dir=keyframes_dir,\n",
    "        )\n",
    "\n",
    "        scenes_json_data = {\n",
    "            \"title\": self.get_video_title(),\n",
    "            \"framerate\": scene_list[0][0].get_framerate(),\n",
    "            \"scenes\": [],\n",
    "        }\n",
    "        for scene_number, scene in enumerate(scene_list, start=1):\n",
    "            scenes_json_data[\"scenes\"].append(\n",
    "                {\n",
    "                    \"scene_number\": scene_number,\n",
    "                    \"start_frame\": scene[0].get_frames(),\n",
    "                    \"end_frame\": scene[1].get_frames(),\n",
    "                    \"start_time\": scene[0].get_timecode(),\n",
    "                    \"end_time\": scene[1].get_timecode(),\n",
    "                    \"keyframes\": [],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        for scene_video_file in scenes_dir.iterdir():\n",
    "            if not scene_video_file.is_file():\n",
    "                continue\n",
    "            scene_match = re.match(r\".*-Scene-(\\d+).mp4\", scene_video_file.name)\n",
    "            if scene_match is None:\n",
    "                continue\n",
    "            scene_number = int(scene_match.group(1))\n",
    "            for scene_data in scenes_json_data[\"scenes\"]:\n",
    "                if scene_data[\"scene_number\"] == scene_number:\n",
    "                    scene_data[\"video_path\"] = str(\n",
    "                        scene_video_file.relative_to(self.config.workdir)\n",
    "                    )\n",
    "\n",
    "        for keyframe_image_file in keyframes_dir.iterdir():\n",
    "            if not keyframe_image_file.is_file():\n",
    "                continue\n",
    "            keyframe_match = re.match(\n",
    "                r\".*-Scene-(\\d+)-(\\d+).jpg\", keyframe_image_file.name\n",
    "            )\n",
    "            if keyframe_match is None:\n",
    "                continue\n",
    "            scene_number = int(keyframe_match.group(1))\n",
    "            keyframe_number = int(keyframe_match.group(2))\n",
    "            for scene_data in scenes_json_data[\"scenes\"]:\n",
    "                if scene_data[\"scene_number\"] == scene_number:\n",
    "                    scene_data[\"keyframes\"].append(\n",
    "                        {\n",
    "                            \"number\": keyframe_number,\n",
    "                            \"path\": str(\n",
    "                                keyframe_image_file.relative_to(self.config.workdir)\n",
    "                            ),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        for scene_data in scenes_json_data[\"scenes\"]:\n",
    "            scene_data[\"keyframes\"] = sorted(\n",
    "                scene_data[\"keyframes\"], key=lambda x: x[\"number\"]\n",
    "            )\n",
    "\n",
    "        with (self.config.workdir / \"scenes.json\").open(\"w\") as fp:\n",
    "            json.dump(scenes_json_data, fp, indent=4)\n",
    "\n",
    "    def add_classifier_labels(self) -> None:\n",
    "        LABEL_MAP = {\n",
    "            0: (\n",
    "                \"CS\",\n",
    "                \"Close-up shot (CS): A relatively small object, e.g., face, hand.\",\n",
    "            ),\n",
    "            1: (\n",
    "                \"ECS\",\n",
    "                \"Extreme close-up shot (ECS): Even a smaller part of an object, e.g., eyes.\",\n",
    "            ),\n",
    "            2: (\"FS\", \"Full shot (FS): Human body in full.\"),\n",
    "            3: (\"LS\", \"Long shot (LS): A long distance.\"),\n",
    "            4: (\"MS\", \"Medium shot (MS): Knees or waist up.\"),\n",
    "        }\n",
    "\n",
    "        model = torch.load(\n",
    "            \"./Pytorch_Classification_50ep.pt\",\n",
    "            map_location=torch.device(\"cpu\"),\n",
    "            weights_only=False,\n",
    "        )\n",
    "        model.eval()\n",
    "\n",
    "        scene_json_data = self.get_scene_data()\n",
    "\n",
    "        image_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((128, 128)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "        for scene_data in scene_json_data[\"scenes\"]:\n",
    "            for keyframe_data in scene_data[\"keyframes\"]:\n",
    "                image = Image.open(self.config.workdir / keyframe_data[\"path\"])\n",
    "                image = image_transform(image)\n",
    "                image = image.unsqueeze(0)\n",
    "                with torch.no_grad():\n",
    "                    pred = model(image)\n",
    "                _, pred = torch.max(pred, 1)\n",
    "                pred = pred.item()\n",
    "                label_name, label_description = LABEL_MAP[pred]\n",
    "            keyframe_data[\"label\"] = {\n",
    "                \"name\": label_name,\n",
    "                \"description\": label_description,\n",
    "            }\n",
    "\n",
    "        with (self.config.workdir / \"scenes_with_labels.json\").open(\"w\") as fp:\n",
    "            json.dump(scene_json_data, fp, indent=4)\n",
    "\n",
    "    def add_keyframe_descriptions(self) -> None:\n",
    "\n",
    "        llama_model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n",
    "        llama_model = MllamaForConditionalGeneration.from_pretrained(\n",
    "            llama_model_id, device_map={\"\": 0}, torch_dtype=torch.bfloat16\n",
    "        )\n",
    "        llama_processor = AutoProcessor.from_pretrained(llama_model_id)\n",
    "\n",
    "        chat_messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\"},\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Can you please describe this image in a few sentences?\",\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        scene_json_data = self.get_scene_data_with_labels()\n",
    "\n",
    "        for scene_data in tqdm(\n",
    "            scene_json_data[\"scenes\"], desc=\"Generating descriptions\"\n",
    "        ):\n",
    "            for keyframe_data in scene_data[\"keyframes\"]:\n",
    "                image = Image.open(self.config.workdir / keyframe_data[\"path\"])\n",
    "\n",
    "                inputs = llama_processor(\n",
    "                    image,\n",
    "                    llama_processor.apply_chat_template(\n",
    "                        chat_messages, add_generation_prompt=True\n",
    "                    ),\n",
    "                    add_special_tokens=False,\n",
    "                    return_tensors=\"pt\",\n",
    "                ).to(llama_model.device)\n",
    "                output = llama_model.generate(**inputs, max_new_tokens=1024)\n",
    "                response = llama_processor.decode(\n",
    "                    output[0][inputs[\"input_ids\"].shape[-1] :]\n",
    "                ).strip()\n",
    "                keyframe_data[\"description\"] = response\n",
    "\n",
    "        with (self.config.workdir / \"scenes_with_descriptions.json\").open(\"w\") as fp:\n",
    "            json.dump(scene_json_data, fp, indent=4)\n",
    "\n",
    "    def create_whisper_transcripts(self) -> None:\n",
    "        whisper_model = whisper.load_model(\"large-v3-turbo\")\n",
    "        transcription_result = whisper_model.transcribe(\n",
    "            str(self.get_video_path()), language=\"English\"\n",
    "        )\n",
    "        with (self.config.workdir / \"transcript.json\").open(\"w\") as fp:\n",
    "            json.dump(transcription_result, fp, indent=4)\n",
    "\n",
    "    def create_summary(self) -> None:\n",
    "        scene_json_data = self.get_scene_data_with_descriptions()\n",
    "        with (self.config.workdir / \"transcript.json\").open() as fp:\n",
    "            transcript_json_data = json.load(fp)\n",
    "\n",
    "        scene_and_transcript_data = []\n",
    "        for scene_data in scene_json_data[\"scenes\"]:\n",
    "            start_time = self.time_str_to_float(scene_data[\"start_time\"])\n",
    "            end_time = self.time_str_to_float(scene_data[\"end_time\"])\n",
    "            scene_and_transcript_data.append(\n",
    "                (start_time, end_time, \"1_scene\", scene_data)\n",
    "            )\n",
    "\n",
    "        for segment_data in transcript_json_data[\"segments\"]:\n",
    "            start_time = segment_data[\"start\"]\n",
    "            end_time = segment_data[\"end\"]\n",
    "            scene_and_transcript_data.append(\n",
    "                (start_time, end_time, \"2_transcript\", segment_data)\n",
    "            )\n",
    "\n",
    "        scene_and_transcript_data.sort(key=lambda x: x[0:3])\n",
    "\n",
    "        summary = []\n",
    "        summary.append(f\"Video title: {scene_json_data['title']}\")\n",
    "        for start_time, end_time, data_type, data in scene_and_transcript_data:\n",
    "            if data_type == \"1_scene\":\n",
    "                summary.append(\"\")\n",
    "                summary.append(\n",
    "                    f\"Scene {data['scene_number']} from {self.float_to_time_str(start_time)} to {self.float_to_time_str(end_time)}\"\n",
    "                )\n",
    "                for keyframe in data[\"keyframes\"]:\n",
    "                    summary.append(\n",
    "                        f\"    Keyframe shot: {keyframe[\"label\"][\"description\"]}\"\n",
    "                    )\n",
    "                    summary.append(f\"    Keyframe description:\")\n",
    "                    for line in keyframe[\"description\"].splitlines():\n",
    "                        line = line.strip()\n",
    "                        if line:\n",
    "                            summary.append(f\"        {line}\")\n",
    "                    summary.append(f\"End of scene {data['scene_number']}\")\n",
    "            elif data_type == \"2_transcript\":\n",
    "                summary.append(\"\")\n",
    "                summary.append(\n",
    "                    f\"Transcript from {self.float_to_time_str(start_time)} to {self.float_to_time_str(end_time)}\"\n",
    "                )\n",
    "                for line in data[\"text\"].splitlines():\n",
    "                    line = line.strip()\n",
    "                    if line:\n",
    "                        summary.append(f\"    {line}\")\n",
    "                summary.append(f\"End of transcript\")\n",
    "\n",
    "        (self.config.workdir / \"summary.txt\").write_text(\"\\n\".join(summary))\n",
    "\n",
    "    @staticmethod\n",
    "    def time_str_to_float(time_str: str) -> float:\n",
    "        time_parts = time_str.split(\":\")\n",
    "        result = 0\n",
    "        for part in time_parts:\n",
    "            result = result * 60 + float(part)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def float_to_time_str(time_float: float) -> str:\n",
    "        components = []\n",
    "        time_float = int(time_float)\n",
    "        while time_float > 0:\n",
    "            components.append(f\"{time_float % 60:02d}\")\n",
    "            time_float //= 60\n",
    "        components.reverse()\n",
    "        while len(components) < 2:\n",
    "            components.insert(0, \"00\")\n",
    "        return \":\".join(components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarizer = VideoSummarizer.from_youtube_url(\n",
    "#     \"https://www.youtube.com/watch?v=cVkMnskciHU\",\n",
    "#     VideoSummarizerConfig(Path(\"demo-workdir\")),\n",
    "# )\n",
    "summarizer = VideoSummarizer(VideoSummarizerConfig(Path(\"demo-workdir\")))\n",
    "# summarizer.detect_scenes()\n",
    "# summarizer.add_classifier_labels()\n",
    "# summarizer.add_keyframe_descriptions()\n",
    "# summarizer.create_whisper_transcripts()\n",
    "# summarizer.create_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def chat_fn(message, history):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant who answers questions about a video.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Here are the information about the video.\\n\\n\"\n",
    "            + summarizer.get_summary(),\n",
    "        },\n",
    "    ]\n",
    "    for history_item in history:\n",
    "        messages.append(\n",
    "            {\"role\": history_item[\"role\"], \"content\": history_item[\"content\"]}\n",
    "        )\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "    completion = client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    full_answer = completion.choices[0].message.content\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": 'You are a helpful assistant tasked with condensing long answers into short, readable summaries. The entire response should be wrapped in a Markdown code block.\\nGiven a full answer, gives a one-sentence version of the answer and a longer summary broken into short paragraphs, each beginning with an emoji that reflects the topic of this paragraph. If you have a title for a paragraph, use HTML tags to make it eye-catching and having colors that match the emoji, e.g. `<span style=\"color: red; font-weight: bold;\">Paragraph Title</span>` If you have keywords in the body text, use Markdown syntax to make them italic, e.g. `*some keywords*`.',\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Question:\\n{message.strip()}\\nFull Answer:\\n{full_answer}\\nNow, please summarize the answer.\",\n",
    "        },\n",
    "    ]\n",
    "    completion = client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    summarized_answer = completion.choices[0].message.content\n",
    "\n",
    "    # Strip code block\n",
    "    lines = []\n",
    "    for line in summarized_answer.splitlines():\n",
    "        if \"```\" in line:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "\n",
    "    summarized_answer = \"\\n\".join(lines)\n",
    "    history.append({\"role\": \"user\", \"content\": message})\n",
    "    history.append({\"role\": \"assistant\", \"content\": summarized_answer})\n",
    "    return \"\", history\n",
    "\n",
    "\n",
    "summarizer: VideoSummarizer | None = None\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    title = gr.Markdown(\"# Video Summarizer\")\n",
    "    youtube_url_input = gr.Text(value=\"\", label=\"YouTube URL\")\n",
    "    process_video_button = gr.Button(value=\"Process Video\")\n",
    "    download_button = gr.DownloadButton(label=\"Download Texts\", interactive=False)\n",
    "    upload_button = gr.UploadButton(\n",
    "        label=\"Upload Texts\", file_count=\"single\", file_types=[\"text\"]\n",
    "    )\n",
    "    chatbot = gr.Chatbot(type=\"messages\", height=\"70vh\")\n",
    "    message_input = gr.Textbox(label=\"Message\", placeholder=\"Type your message here\")\n",
    "    clear = gr.ClearButton([message_input, chatbot])\n",
    "    message_input.submit(\n",
    "        chat_fn, inputs=[message_input, chatbot], outputs=[message_input, chatbot]\n",
    "    )\n",
    "\n",
    "    def on_process_video_click(youtube_url) -> None:\n",
    "        global summarizer\n",
    "        temp_workdir = Path(tempfile.mkdtemp())\n",
    "        print(f\"Creating temporary working directory at '{temp_workdir}'\")\n",
    "        summarizer = VideoSummarizer.from_youtube_url(\n",
    "            youtube_url, VideoSummarizerConfig(temp_workdir)\n",
    "        )\n",
    "        summarizer.detect_scenes()\n",
    "        summarizer.add_classifier_labels()\n",
    "        summarizer.add_keyframe_descriptions()\n",
    "        summarizer.create_whisper_transcripts()\n",
    "        summarizer.create_summary()\n",
    "        return gr.DownloadButton(\n",
    "            label=\"Download Texts\",\n",
    "            value=summarizer.config.workdir / \"summary.txt\",\n",
    "            interactive=True,\n",
    "        )\n",
    "\n",
    "    process_video_button.click(\n",
    "        on_process_video_click, inputs=youtube_url_input, outputs=download_button\n",
    "    )\n",
    "\n",
    "    def on_upload_click(file) -> None:\n",
    "        global summarizer\n",
    "        original_file_path = Path(file)\n",
    "        temp_workdir = Path(tempfile.mkdtemp())\n",
    "        print(f\"Creating temporary working directory at '{temp_workdir}'\")\n",
    "        (temp_workdir / \"summary.txt\").write_text(original_file_path.read_text())\n",
    "        summarizer = VideoSummarizer(VideoSummarizerConfig(temp_workdir))\n",
    "        return gr.DownloadButton(\n",
    "            label=\"Download Texts\",\n",
    "            value=summarizer.config.workdir / \"summary.txt\",\n",
    "            interactive=True,\n",
    "        )\n",
    "\n",
    "    upload_button.upload(on_upload_click, inputs=upload_button, outputs=download_button)\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
